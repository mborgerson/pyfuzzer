#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import print_function
import subprocess
import threading
import argparse
import time
import struct
import sys
import ctypes
import os
import os.path
import shlex
import select
import binascii

VERBOSE = False
MAP_SIZE = 64*1024
FORKSRV_FD = 198
SHM_ENV_VAR = '__AFL_SHM_ID'


INPUT_FILENAME = '__input_file'

# Determine real path (resolve symbolic links to this script)
ROOT_DIR = os.path.dirname(os.path.abspath(os.path.realpath(__file__ )))

###
### Following code is borrowed from https://github.com/albertz/playground/blob/master/shared_mem.py
### It is used to call into libc to do shared memory mapping
###

libc_so = {"darwin": "libc.dylib", "linux2": ""}[sys.platform]
libc = ctypes.CDLL(libc_so, use_errno=True, use_last_error=True)
shm_key_t = ctypes.c_int
IPC_PRIVATE = 0 # MB: Replace with ftok for uniqueness?
IPC_RMID = 0

# int shmget(key_t key, size_t size, int shmflg);
shmget = libc.shmget
shmget.restype = ctypes.c_int
shmget.argtypes = (shm_key_t, ctypes.c_size_t, ctypes.c_int)

# void* shmat(int shmid, const void *shmaddr, int shmflg);
shmat = libc.shmat
shmat.restype = ctypes.c_void_p
shmat.argtypes = (ctypes.c_int, ctypes.c_void_p, ctypes.c_int)

# int shmdt(const void *shmaddr);
shmdt = libc.shmdt
shmdt.restype = ctypes.c_int
shmdt.argtypes = (ctypes.c_void_p,)

# int shmctl(int shmid, int cmd, struct shmid_ds *buf);
shmctl = libc.shmctl
shmctl.restype = ctypes.c_int
shmctl.argtypes = (ctypes.c_int, ctypes.c_int, ctypes.c_void_p)

# void* memcpy( void *dest, const void *src, size_t count );
memcpy = libc.memcpy
memcpy.restype = ctypes.c_void_p
memcpy.argtypes = (ctypes.c_void_p, ctypes.c_void_p, ctypes.c_size_t)

# void* memcmp( void *dest, const void *src, size_t count );
memcmp = libc.memcmp
memcmp.restype = ctypes.c_int
memcmp.argtypes = (ctypes.c_void_p, ctypes.c_void_p, ctypes.c_size_t)

# key_t ftok(const char *pathname, int proj_id);
ftok = libc.ftok
ftok.restype = shm_key_t
ftok.argtypes = (ctypes.c_char_p, ctypes.c_int)


class SharedMem:
    def __init__(self, size):
        self.size = size
        self.shmid = shmget(IPC_PRIVATE, self.size, 0o600)
        assert self.shmid >= 0
        self.ptr = shmat(self.shmid, 0, 0)
        assert self.ptr

    def remove(self):
        shmdt(self.ptr)
        self.ptr = None
        shmctl(self.shmid, IPC_RMID, 0)
        self.shmid = None

    def __del__(self):
        self.remove()

###
### End
###

class Trace(object):
    """Program execution trace container"""

    def __init__(self, buffer, did_crash, exit_signal, exit_code, duration):
        self._buffer = buffer
        self.did_crash = did_crash
        self.exit_signal = exit_signal
        self.exit_code = exit_code
        self.duration = duration
        self.crc = self._checksum()

    def _checksum(self):
        """Calculate 32-bit checksum over the map buffer"""
        self_ptr = ctypes.cast(self._buffer, ctypes.POINTER(ctypes.c_uint8))
        return binascii.crc32(self_ptr)

    def compare_to(self, other):
        """Determine if this execution was interesting or not"""
        # FIXME: I think this could be better as # of bin changes to create a score
        self_ptr = ctypes.cast(self._buffer, ctypes.POINTER(ctypes.c_uint8))
        other_ptr = ctypes.cast(other._buffer, ctypes.POINTER(ctypes.c_uint8))
        # return memcmp(ctypes.byref(self._buffer), ctypes.byref(other._buffer), MAP_SIZE) == 0

        new_paths = False
        new_bin_change = False
        for i in range(MAP_SIZE):
            # did this input exercise new paths?
            # FIXME: redundant, we can roll this condition into the below...
            if other_ptr[i] == 0 and self_ptr[i] != 0:
                new_paths = True

            # did this input move tuple to new bin?
            if self.find_msb(self_ptr[i]) > self.find_msb(other_ptr[i]):
                new_bin_change = True

        return new_paths or new_bin_change
    
    def get_number_of_paths(self):
        """Determine how many paths were taken by counting present tuples"""
        ptr = ctypes.cast(self._buffer, ctypes.POINTER(ctypes.c_uint8))
        num_paths = 0
        for i in range(MAP_SIZE):
            if ptr[i] != 0:
                num_paths += 1
        return num_paths

    def combine_total_paths(self, other):
        """Combine other with this trace to determine total paths"""
        self_ptr = ctypes.cast(self._buffer, ctypes.POINTER(ctypes.c_uint8))
        other_ptr = ctypes.cast(other._buffer, ctypes.POINTER(ctypes.c_uint8))
        for i in range(MAP_SIZE):
            self_ptr[i] = max(self_ptr[i], other_ptr[i])

    def dump_map(self):
        print('Shared Memory:')
        for i in range(MAP_SIZE/16):
            sys.stdout.write('%04x: ' % (i*16))
            for j in range(16):
                sys.stdout.write('%02x ' % self._buffer[i*16+j])
            sys.stdout.write('\n')

    def find_msb(self, x):
        # Probably REALLY slow... is there a way to put x86 assembly in python? :)
        msb = -1
        while x > 0:
            msb += 1
            x >>= 1
        return msb

class TestCase(object):
    """Test case to execute"""
    def __init__(self, data=None, name='Anon', mutations=''):
        self.data = data or bytearray()
        self.name = name
        self.mutations = mutations
    
    def write_input_file(self, path):
        with open(path, 'wb') as f:
            f.write(self.data)
    
    @classmethod
    def create_from_file(self, path):
        with open(path, 'rb') as f:
            data = bytearray(f.read())
        return TestCase(data, name=os.path.basename(path))

    def clone(self):
         # The slice here forces copy of buffer
        return TestCase(self.data[:], name=self.name, mutations=self.mutations)

class MutationStrategy(object):
    """Generates a test case according to a specific strategy"""

    def __init__(self, seed):
        pass
    
    def get_stats(self):
        """Returns (name, percent_complete)"""
        pass

    def gen_test(self):
        """Returns a new TestCase or None"""
        pass

class NullStrategy(MutationStrategy):
    """Just returns the input seed"""

    def __init__(self, seed):
        self.seed = seed
        self.complete = False
    
    def get_stats(self):
        """Returns (name, percent_complete)"""
        return ('Null', 100 if self.complete else 0)

    def gen_test(self):
        """Returns a new TestCase or None"""
        if self.complete:
            return None
        new_case = self.seed.clone()
        self.complete = True
        return new_case

class SequentialBitFlipStrategy(MutationStrategy):
    """Generates a test case according to sequential bit flipping strategy"""

    def __init__(self, seed):
        self.seed = seed
        self.file_len = len(seed.data)

        if hasattr(seed, 'start_byte_pos'):
            self.byte_pos = seed.start_byte_pos
            self.bit_pos = seed.start_bit_pos
        else:
            self.byte_pos = 0
            self.bit_pos = 0
    
    def get_stats(self):
        """Returns (name, percent_complete)"""
        return ('SeqBitFlip', (int)(100.0 * self.byte_pos / self.file_len))

    def gen_test(self):
        """Returns a new TestCase or None"""
        if self.byte_pos >= self.file_len:
            # Strategy complete
            return None
        new_case = self.seed.clone()
        new_case.data[self.byte_pos] ^= 1 << self.bit_pos
        new_case.mutations += 'flip byte %x, bit %d\n' % (self.byte_pos, self.bit_pos)

        self.bit_pos += 1
        if self.bit_pos > 7:
            self.bit_pos = 0
            self.byte_pos += 1

        # Let's just continue from last mutation instead of flipping every bit every time!
        new_case.start_byte_pos = self.byte_pos
        new_case.start_bit_pos = self.bit_pos

        return new_case

class SequentialAddSubStrategy(MutationStrategy): pass

class SequentialInsertInterestingNumbersStrategy(MutationStrategy):
    """Generates a test case according to sequential bit flipping strategy"""

    def __init__(self, seed):
        self.seed = seed
        self.file_len = len(seed.data)
        self.byte_pos = 0
    
    def get_stats(self):
        """Returns (name, percent_complete)"""
        return ('InsBigNums', (int)(100.0 * self.byte_pos / self.file_len))

    def gen_test(self):
        """Returns a new TestCase or None"""
        if self.byte_pos >= self.file_len-4:
            # Strategy complete
            return None
        new_case = self.seed.clone()
        new_case.data[self.byte_pos:self.byte_pos+4] = b'\xff\xff\xff\x7f'
        new_case.mutations += 'set byte %x to +4 = 0xffffffff\n' % (self.byte_pos)
        self.byte_pos += 1
        return new_case

class SequentialRuns(MutationStrategy):
    """Generates a test case according to adding runs of garbage data"""

    def __init__(self, seed):
        self.seed = seed
        self.file_len = len(seed.data)
        self.byte_pos = 0
        self.run_len = 0
    
    def get_stats(self):
        """Returns (name, percent_complete)"""
        return ('TheRuns', (int)(100.0 * self.byte_pos / self.file_len))

    def gen_test(self):
        """Returns a new TestCase or None"""
        if self.byte_pos >= self.file_len:
            # Strategy complete
            return None
        new_case = self.seed.clone()

        if (self.byte_pos + self.run_len) >= self.file_len:
            self.byte_pos += 1
            self.run_len = 0

        self.run_len = min(self.run_len+1, self.file_len-self.byte_pos)

        for i in range(self.run_len):
            new_case.data[self.byte_pos+i] = b'\xff'

        #new_case.mutations += 'set byte %x to +4 = 0xffffffff\n' % (self.byte_pos)

        return new_case

class Backend(object):
    def __init__(self, target):
        self.target = target
        self._prog = target
        self._args = []
    
    def initialize(self):
        """Init the backend"""
        pass

    def spawn(self):
        """Spawn a new instance of the target"""
        pass

    def wait_for_completion(self, timeout=0):
        """Wait for target process to complete"""
        pass

    def get_last_trace(self):
        """Get the trace recorded by the last execution of the program"""
        pass

    def cleanup(self):
        """Cleanup the backend"""
        pass

class QemuBackend(Backend):
    def __init__(self, target):
        super(QemuBackend, self).__init__(target)
    
    def initialize(self):
        # Init shared memory region
        print('[ * ] Initializing shared memory')
        self._shm = SharedMem(MAP_SIZE)
        self._shm_buf = (ctypes.c_uint8 * MAP_SIZE).from_address(self._shm.ptr)
        for i in range(MAP_SIZE):
            self._shm_buf[i] = 0

        # Init fork server communication fifos
        print('[ * ] Creating fork server FIFOs')

        # FIFO #1: The fork server will read from this fifo before launching a
        # new fork. Stuff in 4 bytes to launch a fork.
        if os.path.exists('forksrv_in'):
            os.unlink('forksrv_in')
        os.mkfifo('forksrv_in')
        self._forksrv_in_fd = os.open('forksrv_in', os.O_RDWR)
        os.dup2(self._forksrv_in_fd, FORKSRV_FD) # QEMU expects this fd to be FORKSRV_FD

        # FIFO #2: The fork server will write to this fifo:
        #          - 4 bytes of garbage at startup to see if it's alive
        #          - The 4 byte pid of the child once it is created
        #          - The 4 byte exit status of child
        if os.path.exists('forksrv_out'):
            os.unlink('forksrv_out')
        os.mkfifo('forksrv_out')
        self._forksrv_out_fd = os.open('forksrv_out', os.O_RDWR)
        os.dup2(self._forksrv_out_fd, FORKSRV_FD+1) # QEMU expects this fd to be FORKSRV_FD+1

        # FIFO #3: Used to pipe data into the process's stdin
        if os.path.exists(INPUT_FILENAME):
            os.unlink(INPUT_FILENAME)
        self._target_in_fd = os.open(INPUT_FILENAME, os.O_RDWR | os.O_CREAT | os.O_EXCL)
        os.dup2(self._target_in_fd, 0)

        cmd = [os.path.join(ROOT_DIR, 'qemu-x86_64'), self._prog] + self._args
        print('[ * ] Launching fork server with command', ' '.join(cmd))
        os.environ[SHM_ENV_VAR] = str(self._shm.shmid)
        self._proc = subprocess.Popen(cmd,
            stdout=open('/dev/null'), # Sink program output to /dev/null
            stderr=open('/dev/null'))
        if VERBOSE:
            print('    Shared Memory Segment Id: %d' % self._shm.shmid)
            print('    Fork server pid: %d' % self._proc.pid)
        print('[ * ] Wating for fork server to become ready... ')
        while True:
            # Tight loop to wait for the fork server to come up. Select on the
            # fifo to see if it's ready yet, and at the same time check to see
            # if the process exited early (probably due to command line args)
            r, w, x = select.select([FORKSRV_FD+1], [], [], 0)
            if len(r) > 0: break
            if self._proc.poll():
                print('[ ! ] Fork server exited prematurely (code %d)' % self._proc.returncode)
                sys.exit(1)
        os.read(FORKSRV_FD+1, 4)

    def spawn(self, stdin_data=None):
        # Pump in test data
        os.lseek(self._target_in_fd, 0, os.SEEK_SET)
        os.write(self._target_in_fd, stdin_data)
        os.ftruncate(self._target_in_fd, len(stdin_data))
        os.lseek(self._target_in_fd, 0, os.SEEK_SET)

        # Clear map
        for i in range(MAP_SIZE):
            self._shm_buf[i] = 0

        # Spawn child
        if VERBOSE: sys.stdout.write('[ * ] Launching')
        self.start = time.time()
        os.write(FORKSRV_FD, '0000')
        inst_pid_enc = os.read(FORKSRV_FD+1, 4)
        self.inst_pid = struct.unpack('<I', inst_pid_enc)[0]
        if VERBOSE: print('(pid = %d)' % pid)
    
    def wait_for_completion(self, timeout=0):
        if timeout > 0:
            # Select on the forkserver output fd to wait for it to signal completion
            # with a timeout
            r, w, x = select.select([FORKSRV_FD+1], [], [], timeout)
            if len(r) == 0:
                print('Hang detected!\n')
                os.kill(self.inst_pid, signal.SIGKILL)
                return None

        # Wait for child to exit
        exit_enc = os.read(FORKSRV_FD+1, 4)
        self.stop = time.time()
        status = struct.unpack('<I', exit_enc)[0]
        if VERBOSE: sys.stdout.write('[ * ] Exit Status: %d ' % status)

        self.exit_signal = status & 0x7f
        self.did_crash = self.exit_signal != 0
        self.exit_code = (status & 0xff00) >> 8
        self.did_core_dump = status & 0x80

    def get_last_trace(self):
        # Create new string buffer and clone map_buf into new buffer
        clone = ctypes.create_string_buffer(MAP_SIZE)
        memcpy(ctypes.byref(clone), self._shm.ptr, MAP_SIZE)
        assert(memcmp(ctypes.byref(clone), self._shm.ptr, MAP_SIZE) == 0)
        return clone
    
    def cleanup(self):
        print('[ * ] Cleaning up')
        if self._proc.poll() is None:
            self._proc.kill()
        os.close(self._forksrv_in_fd)
        os.close(FORKSRV_FD)
        os.unlink('forksrv_in')
        os.close(self._forksrv_out_fd)
        os.close(FORKSRV_FD+1)
        os.unlink('forksrv_out')
        os.close(self._target_in_fd)
        os.unlink(INPUT_FILENAME)
        pass

class ValgrindBackend(Backend):
    def __init__(self, target):
        super(ValgrindBackend, self).__init__(target)
    
    def initialize(self):
        # FIFO #3: Used to pipe data into the process's stdin
        if os.path.exists(INPUT_FILENAME):
            os.unlink(INPUT_FILENAME)
        self._target_in_fd = os.open(INPUT_FILENAME, os.O_RDWR | os.O_CREAT | os.O_EXCL)
        os.dup2(self._target_in_fd, 0)

    def spawn(self, stdin_data=None):
        # Pump in test data
        os.lseek(self._target_in_fd, 0, os.SEEK_SET)
        os.write(self._target_in_fd, stdin_data)
        os.ftruncate(self._target_in_fd, len(stdin_data))
        os.lseek(self._target_in_fd, 0, os.SEEK_SET)

        if VERBOSE: sys.stdout.write('[ * ] Launching')
        self.start = time.time()

        cmd = ['valgrind', '--tool=lackey', '--trace-superblocks=yes', os.path.abspath(self._prog)] + self._args
        if VERBOSE: print('[ * ] Launching process with command', ' '.join(cmd))
        self._proc = subprocess.Popen(cmd,
            stdout=subprocess.PIPE, # Sink program output to /dev/null
            stderr=subprocess.PIPE)
    
    def wait_for_completion(self, timeout=0):
        self._trace = ctypes.create_string_buffer(MAP_SIZE)
        buf = ctypes.cast(self._trace, ctypes.POINTER(ctypes.c_uint8))

        import re

        # Wait for child to exit
        p_stdout, p_stderr = self._proc.communicate()
        # print(p_stdout)
        prev_loc = 0
        for x in re.findall('^SB ([a-fA-F0-9]+)', p_stderr, re.MULTILINE):
            cur_loc  = int(x, 16)
            cur_loc  = (cur_loc >> 4) ^ (cur_loc << 8)
            cur_loc &= MAP_SIZE - 1
            buf[cur_loc ^ prev_loc] = (buf[cur_loc ^ prev_loc] + 1) & 0xff
            prev_loc = cur_loc >> 1

        self.stop = time.time()
        self.did_crash = self._proc.returncode < 0
        self.exit_code = self._proc.returncode
        if VERBOSE: sys.stdout.write('[ * ] Exit Status: %d ' % self.exit_code)
        if self.did_crash:
            self.exit_signal = 0 - self.exit_code
        else:
            self.exit_signal = 0

    def get_last_trace(self):
        return self._trace
    
    def cleanup(self):
        print('[ * ] Cleaning up')
        if self._proc.poll() is None:
            self._proc.kill()
        os.close(self._target_in_fd)
        os.unlink(INPUT_FILENAME)

class Fuzzer(threading.Thread):
    def __init__(self, backend, seed_paths=[], outputdir='output'):
        super(Fuzzer, self).__init__()
        self._backend                 = backend
        self._stop_event              = threading.Event()
        self._time_start              = 0
        self._num_paths               = 0
        self._last_path_time          = 0.0
        self._num_crashes             = 0
        self._last_crash_time         = 0.0
        self._num_executions          = 0
        self._stat_update_interval    = 0.25
        self._stat_update_last        = 0
        self._stat_display_wheel_iter = 0
        self._seeds                   = [TestCase.create_from_file(i) for i in seed_paths]
        self._current_strategy        = None
        self._output_dir              = outputdir
        self._strategies              = [NullStrategy, SequentialBitFlipStrategy] # SequentialRuns, SequentialInsertInterestingNumbersStrategy, SequentialBitFlipStrategy]
        self._test_queue              = []
        self._strategy_queue          = []
    
    def time_elapsed_to_str(self, seconds):
        sec_per_min = 60
        sec_per_hour = sec_per_min * 60
        seconds = int(seconds)
        hours = int(seconds / sec_per_hour)
        seconds -= hours * sec_per_hour
        minutes = int(seconds / sec_per_min)
        seconds -= minutes * sec_per_min
        s = ''
        if hours > 0: s += '%dh' % hours
        if minutes > 0: s += '%dm' % minutes
        s += '%ds' % seconds
        return s

    def display_stats(self):
        wheel_icon = ['[ - ]','[  -]','[ - ]','[-  ]']
        now = time.time()
        sys.stdout.write('\r' + ' ' * 80 + '\r') # Hacky terminal line blanker
        last_path_timestamp = 'N/A'
        if self._last_path_time > 0:
            last_path_timestamp = self.time_elapsed_to_str(now - self._last_path_time)
        last_crash_timestamp = 'N/A'
        if self._last_crash_time > 0:
            last_crash_timestamp = self.time_elapsed_to_str(now - self._last_crash_time)
        strategy_info = ''
        if self._current_strategy:
            strategy_info = '%s (%d%%)' % self._current_strategy.get_stats()
        sys.stdout.write('%s %s, %d execs, %d paths (%s), %d crashes (%s), %d/%d, %s' % (
            wheel_icon[self._stat_display_wheel_iter],
            self.time_elapsed_to_str(now - self._time_start),
            self._num_executions,
            self._num_paths, last_path_timestamp,
            self._num_crashes, last_crash_timestamp,
            len(self._test_queue), len(self._strategy_queue),
            strategy_info))
        self._stat_display_wheel_iter = (self._stat_display_wheel_iter + 1) % len(wheel_icon)
        sys.stdout.flush()

    def init(self):
        # Fire up the backend
        self._backend.initialize()

    def run(self):
        # Perform basic startup tasks
        self.init()

        self._time_start = time.time()
        print('[ * ] Starting! (C-c to exit!)')

        baseline = None
        self._test_queue = [s for s in self._seeds]
        self._strategy_queue = []

        while True:
            if self._stop_event.is_set():
                # A stop was requested!
                break

            if self._current_strategy is None:
                if len(self._strategy_queue) == 0:
                    # Try to fill up local queue
                    if len(self._test_queue) == 0:
                        print('\n[ * ] End of tasks')
                        break
                
                    # Build queue of strategies to try for this queued test case
                    t = self._test_queue.pop(0)
                    self._strategy_queue = [s(t) for s in self._strategies]

                # Get next strategy
                self._current_strategy = self._strategy_queue.pop(0)
            
            # Generate next test case
            test_case = self._current_strategy.gen_test()
            if test_case is None:
                self._current_strategy = None
                continue

            self._backend.spawn(test_case.data)
            self._backend.wait_for_completion()

            if self._backend.did_crash:
                if VERBOSE: print('(Process Terminated, Signal = %d)' % self._backend.exit_signal)
            else:
                if VERBOSE: print('(Exit Normal, Code = %d)' % self._backend.exit_code)
            duration = (self._backend.stop-self._backend.start)
            if VERBOSE: print('[ * ] Process executed for %f seconds' % duration)

            # Create program trace object
            trace = Trace(self._backend.get_last_trace(),
                did_crash=self._backend.did_crash,
                exit_signal=self._backend.exit_signal,
                exit_code=self._backend.exit_code,
                duration=duration)

            if baseline is None:
                baseline = trace

            if self._backend.did_crash:
                self._num_crashes += 1
                self._last_crash_time = time.time()

                # Save this test case
                if not os.path.exists(self._output_dir):
                    os.makedirs(self._output_dir)
                test_case.write_input_file(os.path.join(self._output_dir, 'input_%d' % self._num_crashes))

                # # Move core dump to crash directory
                # for f in os.listdir('.'):
                #     if f.endswith('.core'):
                #         os.rename(f, os.path.join(output_dir_path, os.path.basename(f)))

                # # Save which mutations were done against original seed
                # with open(os.path.join(output_dir_path, 'mutations.txt'), 'wb') as f:
                #     f.write(test_case.mutations)

                # assert trace.compare_to(baseline)

            else:
                # Didn't cause a crash, but could be interesting?
                if trace.compare_to(baseline):
                    print('\nHmm, that\'s interesting...')
                    self._test_queue.append(test_case)

            baseline.combine_total_paths(trace)
            num_paths = baseline.get_number_of_paths()
            if num_paths > self._num_paths:
                self._num_paths = num_paths
                self._last_path_time = time.time()

            del trace

            # Display runtime statistics
            self._num_executions += 1
            if True:#(time.time() - self._stat_update_last) > self._stat_update_interval:
                self._stat_update_last = time.time()
                self.display_stats()

        print('[ * ] Executed %d times' % self._num_executions)

        self.cleanup()

    def stop(self):
        self._stop_event.set()

    def cleanup(self):
        self._backend.cleanup()
        if os.path.exists(INPUT_FILENAME):
            os.unlink(INPUT_FILENAME)

def main():
    a = argparse.ArgumentParser(description='This program performs fuzzing of inputs to an arbitrary binary.')
    a.add_argument('-Q', '--qemu',      help='use Qemu-based fuzzing', action='store_true')
    a.add_argument('-V', '--valgrind',  help='use Valgrind-based fuzzing', action='store_true')
    a.add_argument('-i', '--inputdir',  help='seed input directory', required=True)
    a.add_argument('-o', '--outputdir', help='output data directory')
    a.add_argument('--verbose',         help='print debug output', action='store_true')
    a.add_argument('target',            help='path to target binary')
    a.set_defaults(inputdir='', outputdir='output')
    args = a.parse_args()

    # Enable verbose logging
    global VERBOSE
    VERBOSE = args.verbose

    if args.qemu == args.valgrind:
        # Neither or both were selected!
        sys.stderr.write('error: please select Qemu (-Q) OR Valgrind (-V)\n')
        sys.exit(1)

    # Create the backend
    backend = None
    if args.qemu:
        backend = QemuBackend(args.target)
    elif args.valgrind:
        backend = ValgrindBackend(args.target)
    else:
        raise Exception('No backend')

    # Gather inputs from inputdir
    seed_paths = []
    if args.inputdir:
        seed_paths = [os.path.join(args.inputdir, p) for p in os.listdir(args.inputdir)]

    p = Fuzzer(backend, seed_paths, args.outputdir)

    try:
        p.start()
        while p.isAlive():
            p.join(1)
    except KeyboardInterrupt as e:
        p.stop()
    p.stop()

if __name__ == '__main__':
    main()